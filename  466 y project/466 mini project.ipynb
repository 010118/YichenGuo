{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74cb539",
   "metadata": {},
   "source": [
    "## Cmput 466 project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d791afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_ratio = 0.4\n",
    "\n",
    "attribute = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"]\n",
    "point = 'quality'\n",
    "\n",
    "def getData(wine_type):\n",
    "    if wine_type == \"red\":\n",
    "        dataset = pd.read_csv(\"winequality-red.csv\")\n",
    "        dataset = dataset.sample(frac=1)\n",
    "        \n",
    "        X_all = dataset.drop(\"quality\", axis=1)\n",
    "        y_all = dataset['quality']\n",
    "         \n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    elif wine_type == \"white\":\n",
    "        dataset = pd.read_csv(\"winequality-white.csv\")\n",
    "        dataset = dataset.sample(frac=1)\n",
    "        X_all = dataset[attribute].values.reshape(-1, len(attritube))\n",
    "        y_all = dataset[point].values\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X_all, y_all, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def accuracy(pred, y_test):\n",
    "    correct = sum(1 for p, y in zip(pred, y_test) if p == y)\n",
    "    acc = correct / len(pred)\n",
    "    return acc\n",
    "\n",
    "def close_accuracy(pred, y_test):\n",
    "    close = sum(1 for p, y in zip(pred, y_test) if p == y or p + 1 == y or p - 1 == y)\n",
    "    acc = close / len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265659c",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15c8315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Training Evaluation:\n",
      "Mean squared error: 0.5109489051094891\n",
      "Mean absolute error: 0.44421272158498437\n",
      "Accuracy: 0.5881126173096975\n",
      "\n",
      "Testing:\n",
      "Testing Evaluation:\n",
      "Mean squared error: 0.690625\n",
      "Mean absolute error: 0.528125\n",
      "Accuracy: 0.5375\n",
      "Close Accuracy (+-1 score): 0.946875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import utils\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(X_train, y_train)\n",
    "    return LR\n",
    "\n",
    "def evaluate_model(model, X, y, dataset_name):\n",
    "    pred = model.predict(X)\n",
    "    pred_rounded = np.rint(pred)\n",
    "    y_rounded = np.rint(np.array(y))\n",
    "\n",
    "    mse = mean_squared_error(y_rounded, pred_rounded)\n",
    "    mae = mean_absolute_error(y_rounded, pred_rounded)\n",
    "    accuracy = utils.accuracy(pred_rounded, y_rounded)\n",
    "\n",
    "    print(f\"{dataset_name} Evaluation:\")\n",
    "    print(f\"Mean squared error: {mse}\")\n",
    "    print(f\"Mean absolute error: {mae}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    if dataset_name == \"Testing\":\n",
    "        print(\"Close Accuracy (+-1 score): \" + str(utils.close_accuracy(pred_rounded, y_rounded)))\n",
    "\n",
    "def main():\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utils.getData(\"red\")\n",
    "    \n",
    "    # Training\n",
    "    model = train_model(X_train, y_train)\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_train_rounded = np.rint(pred_train)\n",
    "    y_train_rounded = np.rint(np.array(y_train))\n",
    "    \n",
    "    print(\"Training:\")\n",
    "    evaluate_model(model, X_train, y_train, \"Training\")\n",
    "\n",
    "    # Validation\n",
    "    best_err = float('inf')\n",
    "    best_model = None\n",
    "    num_batches = 10  # Replace with your actual number of batches\n",
    "    batch_size = len(X_val) // num_batches\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        X_batch = X_val[i * batch_size:(i + 1) * batch_size]\n",
    "        y_batch = y_val[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "        model = train_model(X_batch, y_batch)\n",
    "        pred_val = model.predict(X_batch)\n",
    "        pred_val_rounded = np.rint(pred_val)\n",
    "        y_batch_rounded = np.rint(np.array(y_batch))\n",
    "\n",
    "        err = mean_squared_error(y_batch_rounded, pred_val_rounded)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_model = model\n",
    "\n",
    "    # Testing\n",
    "    print(\"\\nTesting:\")\n",
    "    evaluate_model(best_model, X_test, y_test, \"Testing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd5e7f",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f032fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Training Evaluation:\n",
      "Mean squared error: 32.24504692387904\n",
      "Mean absolute error: 5.6193952033368095\n",
      "Accuracy: 0.0\n",
      "\n",
      "Testing:\n",
      "Testing Evaluation:\n",
      "Mean squared error: 29.378125\n",
      "Mean absolute error: 5.321875\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "import utils\n",
    "\n",
    "def train_logistic_regression(X, y):\n",
    "    logreg = LogisticRegression(max_iter=10000)  # Increase max_iter to avoid convergence warning\n",
    "    logreg.fit(X, y)\n",
    "    return logreg\n",
    "\n",
    "def evaluate_logistic_regression(model, X, y, dataset_name):\n",
    "    pred_prob = model.predict_proba(X)[:, 1]  # Probability of the positive class\n",
    "    pred_binary = np.round(pred_prob)\n",
    "    \n",
    "    mse = mean_squared_error(y, pred_binary)\n",
    "    mae = mean_absolute_error(y, pred_binary)\n",
    "    accuracy = accuracy_score(y, pred_binary)\n",
    "\n",
    "    print(f\"{dataset_name} Evaluation:\")\n",
    "    print(f\"Mean squared error: {mse}\")\n",
    "    print(f\"Mean absolute error: {mae}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "def main():\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utils.getData(\"red\")\n",
    "    \n",
    "    # Training Logistic Regression\n",
    "    logreg_model = train_logistic_regression(X_train, y_train)\n",
    "    pred_train_prob = logreg_model.predict_proba(X_train)[:, 1]  # Probability of the positive class\n",
    "    pred_train_binary = np.round(pred_train_prob)\n",
    "    \n",
    "    print(\"Training:\")\n",
    "    evaluate_logistic_regression(logreg_model, X_train, y_train, \"Training\")\n",
    "\n",
    "    # Validation\n",
    "    best_err = float('inf')\n",
    "    best_logreg_model = None\n",
    "    num_batches = 10  # Replace with your actual number of batches\n",
    "    batch_size = len(X_val) // num_batches\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        X_batch = X_val[i * batch_size:(i + 1) * batch_size]\n",
    "        y_batch = y_val[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "        logreg_model = train_logistic_regression(X_batch, y_batch)\n",
    "        pred_val_prob = logreg_model.predict_proba(X_batch)[:, 1]  # Probability of the positive class\n",
    "        pred_val_binary = np.round(pred_val_prob)\n",
    "\n",
    "        err = mean_squared_error(y_batch, pred_val_binary)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_logreg_model = logreg_model\n",
    "\n",
    "    # Testing\n",
    "    print(\"\\nTesting:\")\n",
    "    evaluate_logistic_regression(best_logreg_model, X_test, y_test, \"Testing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4aca4e",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61032413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Mean squared error: 0.42752867570385816\n",
      "Mean absolute error: 0.3920750782064651\n",
      "Accuracy: 0.6256517205422315\n",
      "\n",
      "Validation:\n",
      "Mean squared error: 0.690625\n",
      "Mean absolute error: 0.453125\n",
      "Accuracy: 0.615625\n",
      "\n",
      "Testing:\n",
      "Mean squared error: 0.621875\n",
      "Mean absolute error: 0.478125\n",
      "Accuracy: 0.58125\n",
      "Close Accuracy (+-1 score): 0.953125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Hyperparameters\n",
    "    degree = 2  \n",
    "    \n",
    "    # training\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utils.getData(\"red\")\n",
    "\n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_val_poly = poly.transform(X_val)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Linear regression with polynomial features\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Training evaluation\n",
    "    pred_train = poly_reg.predict(X_train_poly)\n",
    "    pred_train = np.rint(pred_train)\n",
    "    y_train = np.rint(np.array(y_train))\n",
    "    print(\"Training:\")\n",
    "    print(\"Mean squared error: \" + str(mean_squared_error(y_train, pred_train)))\n",
    "    print(\"Mean absolute error: \" + str(mean_absolute_error(y_train, pred_train)))\n",
    "    print(\"Accuracy: \" + str(utils.accuracy(pred_train, y_train)))\n",
    "\n",
    "    # Validation evaluation\n",
    "    pred_val = poly_reg.predict(X_val_poly)\n",
    "    pred_val = np.rint(pred_val)\n",
    "    y_val_rounded = np.rint(np.array(y_val))\n",
    "    print(\"\\nValidation:\")\n",
    "    print(\"Mean squared error: \" + str(mean_squared_error(y_val_rounded, pred_val)))\n",
    "    print(\"Mean absolute error: \" + str(mean_absolute_error(y_val_rounded, pred_val)))\n",
    "    print(\"Accuracy: \" + str(utils.accuracy(pred_val, y_val)))\n",
    "\n",
    "    # Testing evaluation\n",
    "    pred_test = poly_reg.predict(X_test_poly)\n",
    "    pred_test = np.rint(pred_test)\n",
    "    y_test_rounded = np.rint(np.array(y_test))\n",
    "    print(\"\\nTesting:\")\n",
    "    print(\"Mean squared error: \" + str(mean_squared_error(y_test_rounded, pred_test)))\n",
    "    print(\"Mean absolute error: \" + str(mean_absolute_error(y_test_rounded, pred_test)))\n",
    "    print(\"Accuracy: \" + str(utils.accuracy(pred_test, y_test)))\n",
    "    print(\"Close Accuracy (+-1 score): \" + str(utils.close_accuracy(pred_test, y_test)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c33ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
